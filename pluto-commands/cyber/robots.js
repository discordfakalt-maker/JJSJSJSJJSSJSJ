import { BOT_CONFIG } from '../../config.js';

export default {
    command: 'robots',
    description: 'Verifica robots.txt',
    category: 'cyber',
    
    async execute(msg, args, client) {
        if (!args[0]) {
            await msg.reply('â“ Inserisci un dominio!\nEsempio: /robots example.com');
            return;
        }
        
        const domain = args[0].replace(/^https?:\/\//, '').split('/')[0];
        
        await msg.reply(`
ğŸ¤– *ROBOTS.TXT CHECKER*

ğŸŒ Target: ${domain}

ğŸ“„ File robots.txt:
ğŸ”— https://${domain}/robots.txt

ğŸ“‹ Informazioni:
â”œâ”€ Directory nascoste
â”œâ”€ Sitemap location
â”œâ”€ User-agent rules
â””â”€ Disallow paths

ğŸ’¡ I robots.txt possono rivelare path interessanti!

${BOT_CONFIG.poweredBy}
        `.trim());
    }
};
